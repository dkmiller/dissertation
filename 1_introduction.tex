% !TEX root = Daniel-Miller-thesis.tex

\chapter{Introduction}





\section{Motivation from classical analytic number theory}

Start with an old problem central to number theory---counting 
prime numbers. As usual, let $\pi(x)$ be the prime counting function and 
$\Li(x) = \int_2^x \frac{\dd t}{\log t}$ be the Eulerian logarithmic integral. 
There is a normalized empirical measure 
$P_x = \frac{1}{\pi(x)} \sum_{p\leqslant x} \delta_{p/x}$, capturing the 
distribution of the set of primes $\leqslant x$. The prime number theorem 
tells us that as $x\to \infty$, this empirical measure converges weakly to the 
``true'' measure $L_x = \frac{\Li(t x)}{\Li(x)}\, \dd t$. The standard approach 
to proving the prime number theorem is by showing that the Riemann 
$\zeta$-function has non-vanishing meromorphic continuation past $\Re = 1$.

\begin{theorem}
The function $\zeta(s)$ admits a non-vanishing meromorphic continuation past 
$\Re = 1$ with at most a simple pole at $s=1$, if and only if 
$P_x \to L_x$ in the weak topology as $x\to \infty$. 
\end{theorem}

Since $\zeta(s)$ does have the desired properties, the prime number 
theorem holds. 
It is natural to try to quantify the rate of converge of $P_x$ to $L_x$. One 
way to do this is via the (star) discrepancy 
\[
	\D^\star(P_x,L_x) 
		= \sup_{t\in [0,1]} \left| P_x[0,t] - L_x[0,t]\right|
		= \sup_{t\in [0,1]} \left| \frac{\pi(t x)}{\pi(x)} - \frac{\int_2^{tx} \frac{\dd s}{\log s}}{\int_2^x \frac{\dd s}{\log s}}\right| .
\]
Numerical experiments suggest that 
$\D^\star(P_x,L_x) \ll x^{-\frac 1 2+\epsilon}$, and in fact we have the 
following result. 

\begin{theorem}
The Riemann Hypothesis is true if and only if 
$\D^\star(P_x,L_x) \ll x^{-\frac 1 2+\epsilon}$. 
\end{theorem}

Neither side of this equivalence is known for certain to be true! 

The above discussion finds a natural generalization in Artin $L$-functions. 
Let $K/\bQ$ be a finite Galois extension with group $G=\Gal(K/\bQ)$. For any 
rational prime $p$ at which $K$ is unramified, let $\frob_p$ be the conjugacy 
class of the Frobenius at $p$ in $G$. For any irreducible representation 
$\rho\colon G\to \GL_n(\bC)$, there is a corresponding $L$-function defined as 
\[
	L(\rho,s) = \prod_p \frac{1}{\det(1-\rho(\frob_p) p^{-s})} ,
\]
where here (and for the remainder of this thesis) we tacitly omit from the 
product those primes at which $\rho$ is ramified. Given a cutoff $x$, there is 
a natural empirical measure 
$P_x = \frac{1}{\pi(x)} \sum_{p\leqslant x} \delta_{\frob_p}$ on 
$G^\natural$, the set of conjugacy classes in $G$. Let 
$\D(P_x) = \sup_{S\subset G^\natural} \left| P_x(S) - \frac{\# S}{\# G^\natural}\right|$. 
Then $P_x$ converges weakly to the uniform measure on $G^\natural$ if and 
only if $\D(P_x) \to 0$. 

\begin{theorem}
The measure $P_x$ converge weakly to the uniform measure on $G^\natural$ if and 
only if the function $L(\rho,s)$ admits a nonvanishing analytic continuation 
past $\Re = 1$ for all nontrivial $\rho$. 
\end{theorem}

Both sides of this equivalence are true, and known as the Chebotarev density 
theorem. Moreover, there is a version of the strong prime number theorem in 
this context. 

\begin{theorem}
The bound $\D(P_x) \ll x^{-\frac 1 2+\epsilon}$ holds if and only if each
$L(\rho,s)$, $\rho$ nontrivial, satisfies the Riemann Hypothesis. 
\end{theorem}

This whole discussion generalizes to a more complicated set of Galois 
representations---those arising from elliptic curves and more general motives.  





\section{Discrepancy and Riemann Hypothesis for elliptic curves}

Let $E_{/\bQ}$ be an elliptic curve. For any prime $l$, the $l$-adic Tate 
module of $E$ induces a continuous representation 
$\rho_l \colon G_\bQ \to \GL_2(\bZ_l)$. It is known that the quantities 
$a_p = \tr \rho_l(\frob_p)$ lie in $\bZ$ and satisfy the Hasse bound 
$|a_p| \leqslant 2\sqrt p$. For each unramified prime $p$, the 
corresponding Satake parameter for $E$ is 
$\theta_p = \cos^{-1}\left(\frac{a_p}{2\sqrt p}\right) \in [0,\pi]$. 
These parameters are packaged into an $L$-function as follows:
\[
	L(E,s) = \prod_p \frac{1}{(1 - e^{i \theta_p} p^{-s})(1- e^{-i \theta_p} p^{-s})} = \prod_p \frac{1}{\det\left(1 - \smat{e^{i\theta_p}}{}{}{e^{-i \theta_p}}p^{-s}\right)}.
\]
More generally we have, for each irreducible representation of $\SU(2)$, which 
will be $\sym^k$ for some $k\geqslant 1$, the $k$-th symmetric power 
$L$-function: 
\[
	L(\sym^k E, s) = \prod_p \prod_{j=0}^k \frac{1}{1 - e^{i (k - 2j) \theta_p} p^{-s}} = \prod_p \frac{1}{\det\left(1-\sym^k \smat{e^{i\theta_p}}{}{}{e^{-i \theta_p}}p^{-s}\right)}.
\]

Numerical experiments suggest that the Satake parameters are equidistributed 
with respect to the Sato--Tate distribution 
$\ST = \frac{2}{\pi} \sin^2\theta\, \dd\theta$. Indeed, for any cutoff $x$, let 
$P_x$ be the empirical measure 
$P_x = \frac{1}{\pi(x)} \sum_{p\leqslant x} \delta_{\theta_p}$. 
The convergence of the $P_x$ to the Sato--Tate measure is closely related to 
the analytic properties of the $L(\sym^k E,s)$. First, here is the famous 
Sato--Tate Conjecture (now a theorem) in our notation. 

\begin{theorem}[Taylor et.~al.]
If $E$ is non-CM, the measures $P_x$ converge weakly to $\ST$. 
\end{theorem}

\begin{theorem}[Serre]
The Sato--Tate conjecture holds for (a non-CM) $E$ if and only if each of 
the functions $L(\sym^k E,s)$ have analytic continuation past $\Re = 1$. 
\end{theorem}

The stunning recent proof of the Sato--Tate conjecture 
\cite{clozel-harris-taylor-2008,taylor-2008,harris-shepherd-barron-taylor-2010} 
in fact showed that the functions $L(\sym^k E,s)$ were potentially automorphic, 
which gives the desired analytic continuation. 

The Riemann Hypothesis, and its analogue for Artin $L$-functions, has a natural 
generalization to elliptic curves. In this context, the discrepancy of the set 
$\{\theta_p\}_{p\leqslant x}$ is 
\[
	\D\left(\{\theta_p\}_{p\leqslant x},\ST\right) = \sup_{t\in [0,\pi]} \left| P_x[0,t] - \ST[0,t]\right| .
\]
The following conjecture is first made in \cite{akiyama-tanigawa-1999}: for 
$E_{/\bQ}$ a non-CM elliptic curve, the estimate 
$\D\left(\{\theta_p\}_{p\leqslant x},\ST\right)\ll x^{-\frac 1 2+\epsilon}$ 
holds. The authors go on to prove a special case of the following theorem, 
proved in full generality in \cite{mazur-2008}. 

\begin{theorem}[Mazur]
If $\D\left(\{\theta_p\}_{p\leqslant x},\ST\right)\ll x^{-\frac 1 2+\epsilon}$, 
then all the functions $L(\sym^k E, s)$ satisfy the Riemann Hypothesis. 
\end{theorem}

This discussion also makes sense when $E$ has complex multiplication (for 
simplicity, we consider $E_{/F}$ where $F$ is the field of definition of the 
complex multiplication). The Sato--Tate measure for such $E$ is the Haar 
measure on $\SO(2)$, i.e.~the uniform measure on $[0,\pi]$. Instead of 
symmetric power $L$-functions, there is an $L$-function for each character of 
$\SO(2)$. Once again, ``Akiyama--Tanigawa implies Riemann Hypothesis'' holds. 

It is natural to assume that the converse to the implication 
``Akiyama--Tanigawa implies General Riemann Hypothesis'' holds. David Zywina 
first suggested to the author that it might not. In this thesis, we construct a 
range of counterexamples to the implication ``Strong Sato--Tate implies 
Riemann Hypothesis'' for the case of CM abelian varieties Moreover, we 
generalize the results of \cite{pande-2011} to show that there can be no 
purely Galois-theoretic proof of the Sato--Tate conjecture, for there are 
Galois representations with arbitrary Sato--Tate distributions! We also show 
that some of the results of \cite{sarnak-2007} about sums of the form 
$\sum_{p\leqslant x} \frac{a_p}{\sqrt p}$ cannot be generalized to general 
Galois representations. 





\section{Notation conventions}

Whenever $l$ is mentioned it is a rational prime $\geqslant 7$. 

Write $f\ll g$ if $f = O(g)$, i.e.~there is a constant $C>0$ such that 
$f \leqslant C g$. 

Write $f=\Omega(g)$ (in the convention of Hardy--Littlewood) if 
$\limsup \frac f g > 0$. 

The symbol $f = \Theta(g)$ means there exist constants $0<C_1<C_2$ such that 
$C_1 g \leqslant f \leqslant C_2 g$. Equivalently, $g \ll f$ and $f \ll g$. 

If $\mu$ is a measure on $\bR$, then write $\mu[a,b]$ for $\mu([a,b])$, and 
similarly for $[a,b)$, $(a,b]$, etc. In general, whenever it simplifies the 
notation, we will write $\mu S$ for $\mu(S)$ if $\mu$ is a measure and 
$S$ is a measurable set. 

If $\mu$ is a measure on $\bR$, then \emph{cumulative distribution function 
(cdf) of $\mu$} is given by $\cdf_\mu(x) = \mu[-\infty,x]$. 

If $z\in \bC$, write $\Re z$ for the real part of $z$. 

If $\alpha\in \bR$, we write $\Re > \alpha$ for the half-plane of complex 
numbers with real part $> \alpha$. So a function has analytic continuation to 
the half-plane $\{z\in \bC : \Re z > \alpha\}$ if and only if the function 
extends to $\Re > \alpha$. 

We write $\bx = (x_1,x_2,\dots)$ for infinite sequences and 
$\vx = (x_1,\dots,x_d)$ for vectors. Sometimes we will have a sequence of 
vectors, written as $\bx = (\vx_1,\vx_2,\dots)$. 

If $\bx=(x_1,x_2,\dots)$ is a sequence, write 
$P_{\bx,N} = \frac{1}{N} \sum_{n\leqslant N} \delta_{x_n}$ for the 
corresponding empirical measure. If $\bx=(x_\alpha)$ is instead indexed by 
some other (discrete) subset of $\bR^+$, write 
\[
	P_{\bx,N} = \frac{1}{\# \{\text{indices }\leqslant N\}}\sum_{\alpha \leqslant N} \delta_{x_\alpha} .
\]

Omitted entries in matrices are zero, i.e.~$\smat{a}{}{}{b}$ means 
$\smat{a}{0}{0}{b}$. 
