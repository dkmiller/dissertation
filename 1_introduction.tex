% !TEX root = Daniel-Miller-thesis.tex

\chapter{Introduction}





\section{Motivation from classical analytic number theory}

Start with a problem central to the history of number theory---counting 
prime numbers. As usual, let $\pi(x)$ be the number of rational primes 
$\leqslant x$ and $\Li(x) = \int_2^x \frac{\dd t}{\log t}$ be the 
logarithmic integral. For any $x\geqslant 2$, there is a (normalized) 
empirical measure capturing the distribution of those primes $\leqslant x$: 
\[
	P_x = \frac{1}{\pi(x)} \sum_{p\leqslant x} \delta_{p/x} ,
\]
which is supported on the unit interval $[0,1]$. The prime number theorem 
tells us that as $x\to \infty$, these empirical measures weakly converge to the 
``true'' measure $L_x = \frac{\Li(t x)}{\Li(x)}\, \dd t$. The standard approach 
to proving the prime number theorem is by showing that the Riemann 
$\zeta$-function has meromorphic continuation past $\Re = 1$, with no zeros 
on that line. 

\begin{theorem}
The function $\zeta(s)$ admits a meromorphic continuation past $\Re = 1$ with 
at most a simple pole at $s=1$ and no zeros on $\Re = 1$, if and only if 
$P_x \to L_x$ weakly. 
\end{theorem}

Since $\zeta(s)$ does have the desired properties, the prime number 
theorem holds. 
It is natural to try to quantify the rate of converge of $P_x$ to $L_x$. One 
way to do this is via the (star) discrepancy 
\[
	\disc^\star(P_x,L_x) 
		= \sup_{t\in [0,1]} \left| P_x[0,t] - L_x[0,t]\right|
		= \sup_{t\in [0,1]} \left| \frac{\pi(t x)}{\pi(x)} - \frac{\int_2^{tx} \frac{\dd s}{\log s}}{\int_2^x \frac{\dd s}{\log s}}\right| .
\]
Numerical experiments suggest that 
$\disc^\star(P_x,L_x) \ll x^{-\frac 1 2+\epsilon}$, and in fact we have the 
following result. 

\begin{theorem}
The Riemann Hypothesis is true if and only if 
$\disc^\star(P_x,L_x) \ll x^{-\frac 1 2+\epsilon}$. 
\end{theorem}

Of course, neither side of this equivalence is known for certain to be true! 

The above discussion finds a natural generalization in Artin $L$-functions. 
Let $K/\bQ$ be a finite Galois extension with group $G=\Gal(K/\bQ)$. For any 
irreducible representation $\rho\colon G\to \GL_d(\bC)$, there is a 
corresponding $L$-function defined as 
\[
	L(\rho,s) = \prod_p \frac{1}{\det(1-\rho(\frob_p) p^{-s})} ,
\]
where here (and for the remainder of this thesis) we tacitly omit from the 
product those primes at which $\rho$ is ramified. Given a cutoff $x$, there is 
a natural empirical measure 
\[
	P_x = \frac{1}{\pi(x)} \sum_{p\leqslant x} \delta_{\frob_p} ,
\]
where $\frob_p$ is the $p$-th Frobenius conjugacy class in $G$. Let 
\[
	\disc(P_x) = \sup_{S\subset G^\natural} \left| P_x(S) - \frac{\# S}{\# G^\natural}\right|,
\]
where $G^\natural$ is the set of conjugacy classes in $G$. 

\begin{theorem}
The measure $P_x$ converge weakly to the uniform measure on $G^\natural$ if and 
only if the function $L(\rho,s)$ admits analytic continuation past $\Re =1$ for 
all nontrivial $\rho$. 
\end{theorem}

Both sides of this equivalence are true, and known as the Chebotarev density 
theorem. Moreover, there is a version of the strong Prime Number Theorem in 
this context. 

\begin{theorem}
The bound $\disc(P_x) \ll x^{-\frac 1 2+\epsilon}$ holds if and only if each
$L(\rho,s)$, $\rho$ nontrivial, satisfies the Riemann Hypothesis. 
\end{theorem}

This whole discussion generalizes to a more complicated set of Galois 
representations---those arising from elliptic curves. 





\section{Discrepancy and Riemann Hypothesis for elliptic curves}

Let $E_{/\bQ}$ be an elliptic curve. For any prime $l$, there is an 
$l$-adic Galois representation $\tate_l E$ associated to $E$, known as the 
Tate module. This is a rank-$2$ $\bZ_l$-module with continuous $G_\bQ$-action, 
so it induces a continuous representation 
$\rho_{E,l} \colon G_\bQ \to \GL_2(\bZ_l)$. It is known 
\cite[Th.~V.1.1]{silverman-2009} that the quantities 
$a_p(E) = \tr \rho_l(\frob_p)$ lie in $\bZ$ and satisfy the Hasse bound 
$|a_p(E)| \leqslant 2\sqrt p$. Thus we can define, for each unramified prime 
$p$, the corresponding Satake parameter for $E$: 
\[
	\theta_p(E) = \cos^{-1}\left(\frac{a_p(E)}{2\sqrt p}\right) \in [0,\pi) .
\]
The Satake parameters are packaged into an $L$-function as follows:
\[
	L(E,s) = \prod_p \frac{1}{(1 - e^{i \theta_p(E)} p^{-s})(1- e^{-i \theta_p(E)} p^{-s})} = \prod_p \frac{1}{1 - \det\smat{e^{i\theta_p}}{}{}{e^{-i \theta_p}}p^{-s}}.
\]
More generally we have, for each irreducible representation of $\SU(2)$, which 
will be $\sym^k$ for some $k\geqslant 1$, the $k$-th symmetric power 
$L$-function 
\[
	L(\sym^k E, s) = \prod_p \prod_{j=0}^k \frac{1}{1 - e^{i (k - 2j) \theta_p(E)} p^{-s}} = \prod_p \frac{1}{1-\det \sym^k \smat{e^{i\theta_p}}{}{}{e^{-i \theta_p}}p^{-s}}.
\]

Numerical experiments suggest that the Satake parameters are distributed with 
respect to the Sato--Tate distribution 
$\ST = \frac{2}{\pi} \sin^2\theta\, \dd\theta$. Indeed, for any cutoff $x$, let 
$P_x$ be the empirical measure 
\[
	P_x = \frac{1}{\pi(x)} \sum_{p\leqslant x} \delta_{\theta_p} .
\]
The convergence of the $P_x$ to the Sato--Tate measure is closely related to 
the analytic properties of the $L(\sym^k E,s)$. First, here is the famous 
Sato--Tate Conjecture (now a theorem) in our notation. 

\begin{theorem}[Sato--Tate conjecture]
If $E$ is non-CM, the measures $P_x$ converge weakly to $\ST$. 
\end{theorem}

\begin{theorem}
Let Sato--Tate conjecture holds for (a non-CM) $E$ if and only if each of 
the functions $L(\sym^k E,s)$ have analytic continuation past $\Re = 1$. 
\end{theorem}

The stunning recent proof of the Sato--Tate conjecture 
\cite{clozel-harris-taylor-2008,taylor-2008,harris-shepherd-barron-taylor-2010} 
in fact showed that the functions $L(\sym^k E,s)$ were potentially automorphic, 
which gives analytic continuation. 

The ``usual'' Riemann Hypothesis, and its generalization to Artin 
$L$-functions, have a natural generalization to elliptic curves. In this 
context, the discrepancy of the set $\{\theta_p\}_{p\leqslant x}$ is 
\[
	\disc\left(\{\theta_p\}_{p\leqslant x},\ST\right) = \sup_{t\in [0,\pi]} \left| P_x[0,t] - \ST[0,t]\right| .
\]
The following conjecture is first made in \cite{akiyama-tanigawa-1999}: for 
$E_{/\bQ}$ a non-CM elliptic curve, the bound 
$\disc\left(\{\theta_p\}_{p\leqslant x},\ST\right)\ll x^{-\frac 1 2+\epsilon}$ 
holds. The authors go on to prove what is essentially the following theorem 
(fully fleshed out in \cite{mazur-2008}). 

\begin{theorem}
If $\disc\left(\{\theta_p\}_{p\leqslant x},\ST\right)\ll x^{-\frac 1 2+\epsilon}$, 
then all the functions $L(\sym^k E, s)$ satisfy the Riemann Hypothesis. 
\end{theorem}

This discussion also makes sense when $E$ has complex multiplication (say, 
defined over $\bQ$), but the Sato--Tate measure is instead the Haar measure 
on $\SO(2)$, i.e.~the uniform measure on $[0,\pi]$. Instead of symmetric power 
$L$-functions, one takes $L$-functions for each representation of $\SO(2)$. 

It is natural to assume that the converse to the implication 
``Strong Sato--Tate implies General Riemann Hypothesis'' holds. David Zywina 
first suggested to the author that it might not. In this thesis, we construct a 
range of counterexamples to the implication ``Strong Sato--Tate implies 
Riemann Hypothesis.'' We also construct a broader conjectural framework 
generalizing 
Akiyama--Tanigawa's conjecture to more general motives. Moreover, we generalize 
the results of \cite{pande-2011} to show that there can be no purely 
Galois-theoretic proof of the Sato--Tate conjecture, for the are Galois 
representations with arbitrary Sato--Tate distributions! We also show that 
some of the results of \cite{sarnak-2007} about sums of the form 
$\sum_{p\leqslant x} \frac{a_p}{\sqrt p}$ cannot be generalized to general 
Galois representations. 





\section{Notational conventions}

Throughout, whenever $l$ is mentioned it is a rational prime $\geqslant 7$. 

The symbol $f=\Omega(g)$ (in the convention of Hardy--Littlewood) means 
the negation of $f = O(g)$.

The symbol $f = \Theta(g)$ means there exist non-zero constants $0<C_1<C_2$
such that $C_1 g \leqslant f \leqslant C_2 f$. 

If $\mu$ is a measure on $\bR$, then $\mu[a,b] = \mu([a,b])$ and similarly 
for $[a,b)$, $(a,b])$, etc. 

If $\mu$ is a measure on $\bR$, then \emph{cumulative distribution function of 
$\mu$} is given by $\cdf_\mu(x) = \mu[-\infty,x]$. 

If $z\in \bC$, write $\Re z$ for the real part of $z$. 

If $\alpha\in \bR$, we write $\Re > \alpha$ for the half-plane of complex 
numbers with real part $> \alpha$. 

We write $\bx = (x_1,x_2,\dots)$ for infinite sequences and 
$\vx = (x_1,\dots,x_d)$ for vectors. Sometimes we will have a sequence of 
vectors, written as $\bx = (\vx_1,\vx_2,\dots)$. 
